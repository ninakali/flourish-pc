# Kind of sort of a time capsule

As you might have noticed, this section is not in the table of contents. It is a part of the preface, but unlike previous sections, this one is not addressed to my contemporaries and is highly personal. I will embarrass myself to the fullest, so feel free to continue reading if that's your kind of thing. Otherwise, please proceed to the next section.

# A letter from the Summer of 2022

## A word of an apology (in advance)
As a human, I suck at predicting the future. That's because the future does not care about my plans, hopes and fears; it just comes as it is. If you are reading this, and things are lovely, well, good for you! I hope you will have a few laughs while reading my thoughts about the future. But if my worst fears turned true by the time you read this and the world as I know it is no more, I am very sorry. If that is the case, I hope you are not losing hope.

Either way, before I wish you good luck on the journey of building a computer, I want to show you how the past, the present and the future are looking for me.

## A long glance to the past

Computing is not unique to human species; some primates and birds understand the idea of small numbers and can perform simple calculations. But the computing we have in 2022 AD is certainly unique to our culture, and seems to be tightly intertwined with the very notion of scientific progress.

Our species have existed for about 300 000 years, says Wikipedia. We do not know when exactly we started to care about numbers, but it seems that the idea already floated around some 20 000 years ago. It materialised in notches on bones and wooden tablets. With the adventure of agriculture came the need of serious accounting. I would speculate that precisely those needs pushed humans to create primitive computer devices around 2300 BC (about 4300 years ago from today). Such devices (abaci) are still occasionally in use today for simple accounting tasks. For a long while, the needs of day-to-day computing have been satisfied.

The scientific knowledge, though, kept expanding, and demanded faster and more reliable computational devices. We got out first mechanical computers for astronomy at least 2000 years ago, and our first (very simple) programmable computers at least 800 years ago. In mere 400 years since this moment slide rulers were created, cheap and simple computers capable of almost instantaneous multiplication and division. For their simplicity and price tag, slide rulers dominated in the world of engineering computations for good 350 years.

Such simple devices could not deal well enough with massive computational tasks, though. Be it precise calculations for physics, or budgeting a whole country, you need something bigger, and more powerful. And from the moment of arrival of such devices, it is hard to tell whether the need for better computers was caused by the speed of human progress, or the increase in speed of human progress was cause by better computers. Perhaps, both statements are true.

Whichever is the case, around the break of the 20th century, significant advances in both science and computing technologies accelerated so much the progress looks a bit blurry. First, tabulating machines in 1890 AD, then universal computational elements in 1913, and then the first general-purpose computer in the late 1930s. Commercial computers (1951), transistor computers (1953), integrated circuits (1958), SRAM (1963), microprocessors (1971), Unix release (1973), first personal computers (1974), TCP and internet (1974), The Personal Computer (1981), pocket electronic computers (1984), world wide web (1991), digital mobile phones (1991), Linux operating system (1991), Amazon and eBay (1995), USB bus (1996), Arduino (2003), first Android phone (2008), Raspberry Pi (2012) and Pi Zero (2015), and countless other technologies that have changed our lives, forever.

## Forever is now
I write this document using my portable computer, a 3-year-old notebook. According to the data I could find, it has a reasonably standard processor with a peak performance of around 85 000 DMIPS (that is, 85 000 000 000 abstract operations per second). Thirty years prior, a typical home computer had a performance of around 1 000 000 op/s. Sixty years prior? Mainframes could do 15 000 op/s, and retail computers - about 100 op/s. And I think this is one of the most commonplace illustrations of the exponential growth of computer performance and technological progress I can find today.

The majority of people today either witnessed the advent of incredible technological advancements or were born in a world where such speed of mass production and progress are taken for granted.
